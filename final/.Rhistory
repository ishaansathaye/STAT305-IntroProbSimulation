col = c("blue", "red"),
pch = c(19, 40),
lty = 1)
# -------------------------------------------------------
# Plot the results (base R)
# -------------------------------------------------------
plot(n_values, mse1,
type = "b",              # 'b' means points+lines
pch = 19, col = "blue",
ylim = range(c(mse1, mse2)),
xlab = "Sample Size (n)",
ylab = "Mean Squared Error (MSE)",
main = "Comparing Empirical MSE of Estimators")
lines(n_values, mse2,
type = "b",
pch = 17, col = "red")
legend("topright",
legend = c("Estimator 1 (MLE)", "Estimator 2 (Unbiased)"),
col = c("blue", "red"),
pch = c(20, 17),
lty = 1)
# -------------------------------------------------------
# Plot the results (base R)
# -------------------------------------------------------
plot(n_values, mse1,
type = "b",              # 'b' means points+lines
pch = 19, col = "blue",
ylim = range(c(mse1, mse2)),
xlab = "Sample Size (n)",
ylab = "Mean Squared Error (MSE)",
main = "Comparing Empirical MSE of Estimators")
lines(n_values, mse2,
type = "b",
pch = 17, col = "red")
legend("topright",
legend = c("Estimator 1", "Estimator 2"),
col = c("blue", "red"),
pch = c(19, 17),
lty = 1)
# Make margins a bit larger and point/axis labels bigger
par(mar = c(5, 5, 4, 2) + 0.1)
# Plot the MSE of Estimator 1 (MLE)
plot(n_values, mse1,
type = "o",               # 'o' -> points + lines
pch = 19, col = "blue",
lty = 3,                  # lty=3 -> dotted line
lwd = 2,                  # thicker line
cex = 1.2,                # scale of the points
cex.lab = 1.3,            # scale of axis labels
cex.axis = 1.2,           # scale of axis text
ylim = range(c(mse1, mse2)),
xlab = "Sample Size (n)",
ylab = "Mean Squared Error (MSE)",
main = "Comparing Empirical MSE of Estimators")
# Add the MSE of Estimator 2 (Unbiased)
lines(n_values, mse2,
type = "o",
pch = 17, col = "red",
lty = 3,     # dotted line
lwd = 2,
cex = 1.2)
# Add a legend
legend("topright",
legend = c("Estimator 1 (MLE)", "Estimator 2 (Unbiased)"),
col = c("blue", "red"),
pch = c(19, 17),
lty = c(3, 3),
lwd = 2,
cex = 1.1)
# Make margins a bit larger and point/axis labels bigger
par(mar = c(5, 5, 4, 2) + 0.1)
# Plot the MSE of Estimator 1 (MLE)
plot(n_values, mse1,
type = "o",               # 'o' -> points + lines
pch = 19, col = "blue",
lty = 3,                  # lty=3 -> dotted line
lwd = 2,                  # thicker line
cex = 1.2,                # scale of the points
cex.lab = 1.3,            # scale of axis labels
cex.axis = 1.2,           # scale of axis text
ylim = range(c(mse1, mse2)),
xlab = "Sample Size (n)",
ylab = "Mean Squared Error (MSE)",
main = "Comparing Empirical MSE of Estimators")
# Add the MSE of Estimator 2 (Unbiased)
lines(n_values, mse2,
type = "o",
pch = 17, col = "red",
lty = 3,     # dotted line
lwd = 2,
cex = 1.2)
# Add a legend
legend("topright",
legend = c("Estimator 1 (MLE)", "Estimator 2 (Unbiased)"),
col = c("blue", "red"),
pch = c(19, 17),
lty = c(3, 3),
lwd = 2,
cex = 1.1)
# Make margins a bit larger and point/axis labels bigger
# Plot the MSE of Estimator 1 (MLE)
plot(n_values, mse1,
type = "o",               # 'o' -> points + lines
pch = 19, col = "blue",
lty = 3,                  # lty=3 -> dotted line
lwd = 2,                  # thicker line
cex = 1.2,                # scale of the points
cex.lab = 1.3,            # scale of axis labels
cex.axis = 1.2,           # scale of axis text
ylim = range(c(mse1, mse2)),
xlab = "Sample Size (n)",
ylab = "Mean Squared Error (MSE)",
main = "Comparing Empirical MSE of Estimators")
# Add the MSE of Estimator 2 (Unbiased)
lines(n_values, mse2,
type = "o",
pch = 17, col = "red",
lty = 3,     # dotted line
lwd = 2,
cex = 1.2)
# Add a legend
legend("topright",
legend = c("Estimator 1 (MLE)", "Estimator 2 (Unbiased)"),
col = c("blue", "red"),
pch = c(19, 17),
lty = c(3, 3),
lwd = 2,
cex = 1.1)
set.seed(123)
num_sims <- 10000
true_var <- 10
true_sd  <- sqrt(10)
n_values <- 2:50
# Store empirical MSE for each estimator
mse1 <- numeric(length(n_values))  # for Estimator 1 (MLE)
mse2 <- numeric(length(n_values))  # for Estimator 2 (unbiased)
# -------------------------------------------------------
# Simulation Loop
# -------------------------------------------------------
for (j in seq_along(n_values)) {
n <- n_values[j]
# Store each simulation's estimates
est1_vals <- numeric(num_sims)
est2_vals <- numeric(num_sims)
# Repeat num_sims times
for (i in 1:num_sims) {
# 1) Generate a sample of size n from N(50, sqrt(10))
X <- rnorm(n, mean = 50, sd = true_sd)
# 2) Compute sample mean
X_bar <- mean(X)
# 3) Compute the sum of squared deviations
SS <- sum((X - X_bar)^2)
# 4) Compute the two estimators
est1_vals[i] <- SS / n        # Estimator 1 (MLE)
est2_vals[i] <- SS / (n - 1)  # Estimator 2 (unbiased)
}
# 5) Compute empirical MSE for each estimator
mse1[j] <- mean((est1_vals - true_var)^2)
mse2[j] <- mean((est2_vals - true_var)^2)
}
mse1_k <- mse1 / 1000
mse2_k <- mse2 / 1000
# Make margins a bit larger and point/axis labels bigger
# Plot the MSE of Estimator 1 (MLE)
plot(n_values, mse1_k,
type = "o",               # 'o' -> points + lines
pch = 19, col = "blue",
lty = 3,                  # lty=3 -> dotted line
lwd = 2,                  # thicker line
cex = 1.2,                # scale of the points
cex.lab = 1.3,            # scale of axis labels
cex.axis = 1.2,           # scale of axis text
ylim = range(c(mse1_k, mse2_k)),
xlab = "Sample Size (n)",
ylab = "Mean Squared Error (MSE)",
main = "Comparing Empirical MSE of Estimators")
# Add the MSE of Estimator 2 (Unbiased)
lines(n_values, mse2_k,
type = "o",
pch = 17, col = "red",
lty = 3,     # dotted line
lwd = 2,
cex = 1.2)
# Add a legend
legend("topright",
legend = c("Estimator 1 (MLE)", "Estimator 2 (Unbiased)"),
col = c("blue", "red"),
pch = c(19, 17),
lty = c(3, 3),
lwd = 2,
cex = 1.1)
set.seed(123)
num_sims <- 10000
true_var <- 10
true_sd  <- sqrt(10)
n_values <- 2:50
# Store empirical MSE for each estimator
mse1 <- numeric(length(n_values))  # for Estimator 1 (MLE)
mse2 <- numeric(length(n_values))  # for Estimator 2 (unbiased)
# -------------------------------------------------------
# Simulation Loop
# -------------------------------------------------------
for (j in seq_along(n_values)) {
n <- n_values[j]
# Store each simulation's estimates
est1_vals <- numeric(num_sims)
est2_vals <- numeric(num_sims)
# Repeat num_sims times
for (i in 1:num_sims) {
# 1) Generate a sample of size n from N(50, sqrt(10))
X <- rnorm(n, mean = 50, sd = true_sd)
# 2) Compute sample mean
X_bar <- mean(X)
# 3) Compute the sum of squared deviations
SS <- sum((X - X_bar)^2)
# 4) Compute the two estimators
est1_vals[i] <- SS / n        # Estimator 1 (MLE)
est2_vals[i] <- SS / (n - 1)  # Estimator 2 (unbiased)
}
# 5) Compute empirical MSE for each estimator
mse1[j] <- mean((est1_vals - true_var)^2)
mse2[j] <- mean((est2_vals - true_var)^2)
}
mse1_k <- mse1*1000
mse2_k <- mse2*1000
# Make margins a bit larger and point/axis labels bigger
# Plot the MSE of Estimator 1 (MLE)
plot(n_values, mse1_k,
type = "o",               # 'o' -> points + lines
pch = 19, col = "blue",
lty = 3,                  # lty=3 -> dotted line
lwd = 2,                  # thicker line
cex = 1.2,                # scale of the points
cex.lab = 1.3,            # scale of axis labels
cex.axis = 1.2,           # scale of axis text
ylim = range(c(mse1_k, mse2_k)),
xlab = "Sample Size (n)",
ylab = "Mean Squared Error (MSE)",
main = "Comparing Empirical MSE of Estimators")
# Add the MSE of Estimator 2 (Unbiased)
lines(n_values, mse2_k,
type = "o",
pch = 17, col = "red",
lty = 3,     # dotted line
lwd = 2,
cex = 1.2)
# Add a legend
legend("topright",
legend = c("Estimator 1 (MLE)", "Estimator 2 (Unbiased)"),
col = c("blue", "red"),
pch = c(19, 17),
lty = c(3, 3),
lwd = 2,
cex = 1.1)
set.seed(123)
num_sims <- 10000
true_var <- 10
true_sd  <- sqrt(10)
n_values <- 2:50
# Store empirical MSE for each estimator
mse1 <- numeric(length(n_values))  # for Estimator 1 (MLE)
mse2 <- numeric(length(n_values))  # for Estimator 2 (unbiased)
# -------------------------------------------------------
# Simulation Loop
# -------------------------------------------------------
for (j in seq_along(n_values)) {
n <- n_values[j]
# Store each simulation's estimates
est1_vals <- numeric(num_sims)
est2_vals <- numeric(num_sims)
# Repeat num_sims times
for (i in 1:num_sims) {
# 1) Generate a sample of size n from N(50, sqrt(10))
X <- rnorm(n, mean = 50, sd = true_sd)
# 2) Compute sample mean
X_bar <- mean(X)
# 3) Compute the sum of squared deviations
SS <- sum((X - X_bar)^2)
# 4) Compute the two estimators
est1_vals[i] <- SS / n        # Estimator 1 (MLE)
est2_vals[i] <- SS / (n - 1)  # Estimator 2 (unbiased)
}
# 5) Compute empirical MSE for each estimator
mse1[j] <- mean((est1_vals - true_var)^2)
mse2[j] <- mean((est2_vals - true_var)^2)
}
mse1_k <- mse1*100
mse2_k <- mse2*100
# Make margins a bit larger and point/axis labels bigger
# Plot the MSE of Estimator 1 (MLE)
plot(n_values, mse1_k,
type = "o",               # 'o' -> points + lines
pch = 19, col = "blue",
lty = 3,                  # lty=3 -> dotted line
lwd = 2,                  # thicker line
cex = 1.2,                # scale of the points
cex.lab = 1.3,            # scale of axis labels
cex.axis = 1.2,           # scale of axis text
ylim = range(c(mse1_k, mse2_k)),
xlab = "Sample Size (n)",
ylab = "Mean Squared Error (MSE)",
main = "Comparing Empirical MSE of Estimators")
# Add the MSE of Estimator 2 (Unbiased)
lines(n_values, mse2_k,
type = "o",
pch = 17, col = "red",
lty = 3,     # dotted line
lwd = 2,
cex = 1.2)
# Add a legend
legend("topright",
legend = c("Estimator 1 (MLE)", "Estimator 2 (Unbiased)"),
col = c("blue", "red"),
pch = c(19, 17),
lty = c(3, 3),
lwd = 2,
cex = 1.1)
# Plot the MSE of Estimator 1 (MLE)
plot(n_values, mse1_k,
type = "o",
pch = 19, col = "blue",
lty = 3,
lwd = 2,
cex = 1.2,
cex.lab = 1.3,
cex.axis = 1.2,
ylim = range(c(mse1_k, mse2_k)),
xlab = "Sample Size (n)",
ylab = "Mean Squared Error (MSE)",
main = "Comparing Empirical MSE of Estimators")
# Add the MSE of Estimator 2 (Unbiased)
lines(n_values, mse2_k,
type = "o",
pch = 17, col = "red",
lty = 3,
lwd = 2,
cex = 1.2)
# Legend
legend("topright",
legend = c("Estimator 1", "Estimator 2"),
col = c("blue", "red"),
pch = c(19, 17),
lty = c(3, 3),
lwd = 2,
cex = 1.1)
# Setup global options
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
# Simulate X1
set.seed(123)
x1 <- rnorm(n = 100000, mean = 2, sd = 1)
head(x1)
# Simulate X2
x2 <- rnorm(n = 100000, mean = 3, sd = 2)
head(x2)
# Simulate X3
x3 <- rnorm(n = 100000, mean = 4, sd = 3)
head(x3)
# Define Z
z <- x1 + x2 + x3
head(z)
# Histogram with probability = TRUE
hist(z,
probability = TRUE,
breaks = 50,
main = "Histogram of Z",
xlab = "Z")
hist(z,
probability = TRUE,
breaks = 50,
main = "Histogram of Z",
xlab = "Z")
# Parameters for Z
mu_Z <- 2 + 3 + 4
sigma_Z <- sqrt(1^2 + 2^2 + 3^2)
# X-values covering the range of z
x_vals <- seq(min(z), max(z), length.out = 1000)
# Add the theoretical PDF curve
lines(x_vals,
dnorm(x_vals, mean = mu_Z, sd = sigma_Z),
col = "blue",
lwd = 2)
# Rate parameter for the Exponential distribution
lambda <- 0.1
# Mean and standard deviation for the Exponential distribution.
mean_exp <- 1 / lambda
sd_exp   <- 1 / lambda
cat("Exponential Distribution Mean:", mean_exp, "\n")
cat("Exponential Distribution SD:", sd_exp, "\n")
set.seed(123)
# sample size
n <- 9
num_samples <- 100000
# 100,000 random samples of size 9 and compute the sample means.
sample_means_n9 <- replicate(num_samples, mean(rexp(n, rate = lambda)))
# Relative frequency histogram of the sample means
hist(sample_means_n9, probability = TRUE, breaks = 50,
main = "Histogram of Sample Means (n = 9)",
xlab = "Sample Mean", col = "lightgray")
# Theoretical sampling distribution parameters for n = 9:
mu   <- mean_exp
se_n9 <- sd_exp / sqrt(n)
# Generate x-values spanning the range of the sample means
x_vals <- seq(min(sample_means_n9), max(sample_means_n9), length.out = 1000)
# Overlay the theoretical normal pdf on the histogram
lines(x_vals, dnorm(x_vals, mean = mu, sd = se_n9), col = "blue", lwd = 2)
set.seed(123)
# sample size
n <- 100
# 100,000 random samples of size 100 and compute the sample means.
sample_means_n100 <- replicate(num_samples, mean(rexp(n, rate = lambda)))
# Relative frequency histogram of the sample means
hist(sample_means_n100, probability = TRUE, breaks = 50,
main = "Histogram of Sample Means (n = 100)",
xlab = "Sample Mean", col = "lightgray")
# Theoretical sampling distribution parameters for n = 100:
se_n100 <- sd_exp / sqrt(n)
# Generate x-values spanning the range of the sample means
x_vals <- seq(min(sample_means_n100), max(sample_means_n100), length.out = 1000)
# Overlay the theoretical normal pdf on the histogram
lines(x_vals, dnorm(x_vals, mean = mu, sd = se_n100), col = "red", lwd = 2)
set.seed(123)
num_sims <- 10000
true_var <- 10
true_sd  <- sqrt(10)
n_values <- 2:50
# Store empirical MSE for each estimator
mse1 <- numeric(length(n_values))  # for Estimator 1 (MLE)
mse2 <- numeric(length(n_values))  # for Estimator 2 (unbiased)
for (j in seq_along(n_values)) {
n <- n_values[j]
# Store each estimate
est1_vals <- numeric(num_sims)
est2_vals <- numeric(num_sims)
# Repeat 10000 times
for (i in 1:num_sims) {
# Make a sample of size n from N(50, sqrt(10))
X <- rnorm(n, mean = 50, sd = true_sd)
# Get sample mean
X_bar <- mean(X)
# Sum of squared deviations
SS <- sum((X - X_bar)^2)
# Compute the two estimators
est1_vals[i] <- SS / n        # Estimator 1 (MLE)
est2_vals[i] <- SS / (n - 1)  # Estimator 2 (unbiased)
}
# Compute empirical MSE for each estimator
mse1[j] <- mean((est1_vals - true_var)^2)
mse2[j] <- mean((est2_vals - true_var)^2)
}
# Match scale of given graph
mse1_k <- mse1*100
mse2_k <- mse2*100
# Plot the MSE of Estimator 1 (MLE)
plot(n_values, mse1_k,
type = "o",
pch = 19, col = "blue",
lty = 3,
lwd = 2,
cex = 1.2,
cex.lab = 1.3,
cex.axis = 1.2,
ylim = range(c(mse1_k, mse2_k)),
xlab = "Sample Size (n)",
ylab = "Mean Squared Error (MSE)",
main = "Comparing Empirical MSE of Estimators")
# Add the MSE of Estimator 2 (Unbiased)
lines(n_values, mse2_k,
type = "o",
pch = 17, col = "red",
lty = 3,
lwd = 2,
cex = 1.2)
# Legend
legend("topright",
legend = c("Estimator 1", "Estimator 2"),
col = c("blue", "red"),
pch = c(19, 17),
lty = c(3, 3),
lwd = 2,
cex = 1.1)
set.seed(123)
# sample size
n <- 9
num_samples <- 100000
# 100,000 random samples of size 9 and compute the sample means.
sample_means_n9 <- replicate(num_samples, mean(rexp(n, rate = lambda)))
# Relative frequency histogram of the sample means
hist(sample_means_n9, probability = TRUE, breaks = 50,
main = "Histogram of Sample Means (n = 9)",
xlab = "Sample Mean", col = "lightgray")
# Theoretical sampling distribution parameters for n = 9:
mu   <- mean_exp
se_n9 <- sd_exp / sqrt(n)
# Generate x-values spanning the range of the sample means
x_vals <- seq(min(sample_means_n9), max(sample_means_n9), length.out = 1000)
# Overlay the theoretical normal pdf on the histogram
lines(x_vals, dnorm(x_vals, mean = mu, sd = se_n9), col = "blue", lwd = 2)
set.seed(123)
# sample size
n <- 100
# 100,000 random samples of size 100 and compute the sample means.
sample_means_n100 <- replicate(num_samples, mean(rexp(n, rate = lambda)))
# Relative frequency histogram of the sample means
hist(sample_means_n100, probability = TRUE, breaks = 50,
main = "Histogram of Sample Means (n = 100)",
xlab = "Sample Mean", col = "lightgray")
# Theoretical sampling distribution parameters for n = 100:
se_n100 <- sd_exp / sqrt(n)
# Generate x-values spanning the range of the sample means
x_vals <- seq(min(sample_means_n100), max(sample_means_n100), length.out = 1000)
# Overlay the theoretical normal pdf on the histogram
lines(x_vals, dnorm(x_vals, mean = mu, sd = se_n100), col = "red", lwd = 2)
